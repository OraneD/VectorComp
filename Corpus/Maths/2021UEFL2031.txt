Le sujet de cette thèse est l'analyse de divers algorithmes stochastiques visant à résoudre un problème d'optimisation non convexe. Nous commençons par un problème d'optimisation lisse en analysant une famille d'algorithmes adaptatifs avec moments qui comprend entre autres ADAM et la descente de gradient accélérée de Nesterov. La convergence et la fluctuation des itérés sont établies. Un résultat général d'évitement des pièges pour les algorithmes stochastiques sous-tendus par une équation différentielle non autonome est présenté. Il est appliqué pour établir la non-convergence des itérés aux points-selles. La suite du manuscrit est consacrée au cas où la fonction que l'on cherche à minimiser est non lisse. La plupart de nos résultats dans cette partie s'appliquent aux fonctions définissables dans une structure o-minimale. Tout d'abord, nous analysons la version à pas constants de la descente de sous-gradient stochastique (SGD) et montrons que ses itérés convergent en grande probabilité vers l'ensemble des points critiques. Deuxièmement, nous montrons que chaque point critique d'une fonction Lipschitz, définissable, générique se trouve sur une variété active, satisfaisant une condition de Verdier et d'angle et est soit un minimum local, un point selle actif ou un point critique fortement répulsif. Nous montrons, sous des conditions légères sur les perturbations, que le SGD évite les deux derniers types de points. Une amélioration de la formule de projection pour les fonctions définissables, donnant une condition de type Lipschitz sur ses sous-gradients de Clarke, est présentée. Enfin, nous établissons un phénomène d'oscillation des itérés du SGD et de ses extensions proximales