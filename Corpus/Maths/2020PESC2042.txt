Les progrès technologiques de ces dernières décennies ont considérablement accru nos capacités à collecter et sauvegarder une quantité importante d’information. Les répercussions, sur de nombreux domaines scientifiques, ont été fulgurantes. En analyse statistique par exemple, de nombreux résultats obtenus sous le canevas habituel d’étude en petite dimension, ont dû être étendus. La littérature scientifique abonde maintenant de nombreux résultats qui ont été mis en exergue, en prenant en compte cette nouvelle réalité qu’est la présence des données en grande dimension. Nos travaux s’inscrivent dans cette droite lignée. En effet, cette thèse aborde le concept d’importance de variables, c’est-à-dire un canevas permettant de déterminer la portée d’une variable. Il s’agit là d’un point crucial dans cette nouvelle ère de données de grande taille. À titre d’exemple, ce concept est largement utilisé dans des modèle de prédiction afin d’améliorer le choix des variables explicatives. Nos contributions peuvent être divisées en trois parties.Dans la première partie, nous introduisons une mesure multivariée dénommée mesure de l’importance de variable, définit en tant que paramètre statistique, assujettie à des modèles de structures marginaux. Nous nous sommes appuyés sur des modèles semi-paramétriques pour son analyse. Cette mesure permet notamment de quantifier la pertinence d’une variable explicative sur une réponse, en prenant en compte le reste des variables du problème. Le paramètre d’intérêt est étudié grâce à la méthode du TMLE (Tartgeted Minimum Loss Estimation). Nous effectuons son analyse théorique complète et sommes ainsi en mesure d’établir la consistance de notre estimateur, ainsi que sa convergence asymptotique. Ce dernier résultat nous permet donc de déduire les intervalles de confiance liés à l’estimateur. Nous effectuons également une analyse numérique afin d’illustrer nos résultats théoriques. A cet effet, nous avons étendu l’implémentation du package TMLE.NPVI, de telle sorte qu’il puisse traiter des cas où le paramètre d’intérêt est multivarié.Dans la seconde partie de cette thèse, nous introduisons une mesure de l’importance de variable définie au travers d’un modèle de régression non-paramétrique en grande dimension. Cette mesure provient en partie de celle introduite dans la première partie, sans la contrainte supplémentaire que l’utilisateur doive fournir un modèle de structure marginal. Au delà, nous considérons également le cas où les données de notre échantillon sont polluées.En s’appuyant sur une décomposition finie sur une base orthonormée du type basede Fourier ou Splines par exemple, et en utilisant la méthode dite du Lasso, nous établissons les vitesses de convergence de notre estimateur. Nous mettons aussi en exergue l’impact des erreurs de mesure, dans notre design, sur ces vitesses de convergence. Au-delà nous proposons également une étude numérique basée sur des données synthétiques et une application, s’appuyant sur des données financières réelles.Dans la troisième et dernière partie, nous considérons une mesure d’importance de variable définie grâce à un modèle de régression linéaire soumis à des erreurs de mesure sur son échantillon. Ce modèle de régression trouve son origine dans la partie précédente. L’estimation de notre paramètre d’intérêt s’effectue au travers d’un problème d’optimisation convexe, obtenu en projetant la covariance empirique du design sur l’ensemble de matrices définies positives, et en utilisant la pénalisation Slope. Nous effectuons ainsi une analyse théorique et numérique complète. Au delà, nous établissons les conditions suffisantes, assez restrictives concernant les erreurs, à respecter afin d’atteindre des vitesses optimales de convergence de notre paramètre d’intérêt, tout en mettant l’accent sur l’impact de la pollution de notre échantillon sur ces vitesses