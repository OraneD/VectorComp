Au cours des dernières décennies, la quantité de données relatives aux risques côtiers a fortement augmenté avec l'installation de nombreux réseaux de surveillance. Dans cette ère de big data, l'utilisation de méthodes d'apprentissage statistique dans le développement de modèles prédictifs locaux devient de plus en plus légitime et justifiée. L'objectif de cette thèse est de démontrer comment les méthodes d'apprentissage statistique peuvent contribuer à l'amélioration des outils d'évaluation des risques côtiers et au développement d'un système d'alerte précoce qui vise à réduire le risque d'inondation côtière. Trois méthodologies ont été développées et testées sur différent sites d'étude. La première méthodologie vise à améliorer les prévisions locales de vagues faites par un modèle spectral de vagues avec des méthodes d'apprentissage automatique et des données provenant de réseaux de surveillance. Nous avons montré que l'assimilation de données avec des méthodes d'apprentissage automatique améliore de manière significative la prévision des paramètres des vagues, en particulier la hauteur et la période des vagues. La deuxième méthodologie concerne la création de bases de données sur l'impact des tempêtes. Bien que ces bases de données soient essentielles dans le processus de réduction des risques de catastrophes, elles sont rares et peu nombreuses. Nous avons donc proposé une méthodologie basée sur une méthode d'apprentissage profond (réseaux de neurones convolutifs) pour générer automatiquement des données qualitatives sur l'impact des tempêtes à partir d'images fournies par des stations de surveillance vidéo installées sur les côtes. La dernière méthodologie concerne le développement d'un modèle d'impact de tempêtes avec une méthode statistique (réseau bayésien) basée exclusivement sur des données acquises avec divers réseaux de surveillance. Grâce à cette méthodologie, nous avons pu prédire de manière qualitative l'impact de tempêtes sur notre site d'étude, la Grande Plage de Biarritz.